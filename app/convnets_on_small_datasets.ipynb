{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "### 5.2 - Using convnets with small datasets\nYou can download the original dataset at: https://www.kaggle.com/c/dogs-vs-cats/data\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import os, shutil",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% \n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "# The path to the directory where the original\n# dataset was uncompressed\noriginal_dataset_dir \u003d \u0027/Users/fchollet/Downloads/kaggle_original_data\u0027\n\n# The directory where we will\n# store our smaller dataset\nbase_dir \u003d \u0027/Users/fchollet/Downloads/cats_and_dogs_small\u0027\nos.mkdir(base_dir)\n\n# Directories for our training,\n# validation and test splits\ntrain_dir \u003d os.path.join(base_dir, \u0027train\u0027)\nos.mkdir(train_dir)\nvalidation_dir \u003d os.path.join(base_dir, \u0027validation\u0027)\nos.mkdir(validation_dir)\ntest_dir \u003d os.path.join(base_dir, \u0027test\u0027)\nos.mkdir(test_dir)\n\n# Directory with our training cat pictures\ntrain_cats_dir \u003d os.path.join(train_dir, \u0027cats\u0027)\nos.mkdir(train_cats_dir)\n\n# Directory with our training dog pictures\ntrain_dogs_dir \u003d os.path.join(train_dir, \u0027dogs\u0027)\nos.mkdir(train_dogs_dir)\n\n# Directory with our validation cat pictures\nvalidation_cats_dir \u003d os.path.join(validation_dir, \u0027cats\u0027)\nos.mkdir(validation_cats_dir)\n\n# Directory with our validation dog pictures\nvalidation_dogs_dir \u003d os.path.join(validation_dir, \u0027dogs\u0027)\nos.mkdir(validation_dogs_dir)\n\n# Directory with our validation cat pictures\ntest_cats_dir \u003d os.path.join(test_dir, \u0027cats\u0027)\nos.mkdir(test_cats_dir)\n\n# Directory with our validation dog pictures\ntest_dogs_dir \u003d os.path.join(test_dir, \u0027dogs\u0027)\nos.mkdir(test_dogs_dir)\n\n# Copy first 1000 cat images to train_cats_dir\nfnames \u003d [\u0027cat.{}.jpg\u0027.format(i) for i in range(1000)]\nfor fname in fnames:\n    src \u003d os.path.join(original_dataset_dir, fname)\n    dst \u003d os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)\n\n# Copy next 500 cat images to validation_cats_dir\nfnames \u003d [\u0027cat.{}.jpg\u0027.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src \u003d os.path.join(original_dataset_dir, fname)\n    dst \u003d os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy next 500 cat images to test_cats_dir\nfnames \u003d [\u0027cat.{}.jpg\u0027.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src \u003d os.path.join(original_dataset_dir, fname)\n    dst \u003d os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy first 1000 dog images to train_dogs_dir\nfnames \u003d [\u0027dog.{}.jpg\u0027.format(i) for i in range(1000)]\nfor fname in fnames:\n    src \u003d os.path.join(original_dataset_dir, fname)\n    dst \u003d os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy next 500 dog images to validation_dogs_dir\nfnames \u003d [\u0027dog.{}.jpg\u0027.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src \u003d os.path.join(original_dataset_dir, fname)\n    dst \u003d os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \n# Copy next 500 dog images to test_dogs_dir\nfnames \u003d [\u0027dog.{}.jpg\u0027.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src \u003d os.path.join(original_dataset_dir, fname)\n    dst \u003d os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "In [4]:\nprint(\u0027total training cat images:\u0027, len(os.listdir(train_cats_dir)))\ntotal training cat images: 1000\n\nIn [5]:\nprint(\u0027total training dog images:\u0027, len(os.listdir(train_dogs_dir)))\ntotal training dog images: 1000\n\nIn [6]:\nprint(\u0027total validation cat images:\u0027, len(os.listdir(validation_cats_dir)))\ntotal validation cat images: 500\n\nIn [7]:\nprint(\u0027total validation dog images:\u0027, len(os.listdir(validation_dogs_dir)))\ntotal validation dog images: 500\n\nIn [8]:\nprint(\u0027total test cat images:\u0027, len(os.listdir(test_cats_dir)))\ntotal test cat images: 500\n\nIn [9]:\nprint(\u0027total test dog images:\u0027, len(os.listdir(test_dogs_dir)))\ntotal test dog images: 500\n\n# Building our network\n\n### Convolution Layer\nA convolution layer allows for one extract features from data using filters.\n\n### MaxPooling Layer\nA maxpooling layer allows for one to down-sample the features, which allows for more approximation as we want the\nnetwork to understand a pattern, but not exactly where the pattern should be located on a image. It allows for \ngeneralization from the data.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from keras import layers\nfrom keras import models\n\nmodel \u003d models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation\u003d\u0027relu\u0027,\n                        input_shape\u003d(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation\u003d\u0027relu\u0027))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation\u003d\u0027relu\u0027))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation\u003d\u0027relu\u0027))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation\u003d\u0027relu\u0027))\nmodel.add(layers.Dense(1, activation\u003d\u0027sigmoid\u0027))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "from keras import optimizers\n\nmodel.compile(loss\u003d\u0027binary_crossentropy\u0027,\n              optimizer\u003doptimizers.RMSprop(lr\u003d1e-4),\n              metrics\u003d[\u0027acc\u0027])\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\n\n# All images will be rescaled by 1./255\ntrain_datagen \u003d ImageDataGenerator(rescale\u003d1./255,\n                                    rotation_range\u003d40,\n                                    width_shift_range\u003d0.2,\n                                    height_shift_range\u003d0.2,\n                                    shear_range\u003d0.2,\n                                    zoom_range\u003d0.2,\n                                    horizontal_flip\u003dTrue,\n                                    fill_mode\u003d\u0027nearest\u0027)\ntest_datagen \u003d ImageDataGenerator(rescale\u003d1./255)\n\ntrain_generator \u003d train_datagen.flow_from_directory(\n        # This is the target directory\n        train_dir,\n        # All images will be resized to 150x150\n        target_size\u003d(150, 150),\n        batch_size\u003d20,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode\u003d\u0027binary\u0027)\n\nvalidation_generator \u003d test_datagen.flow_from_directory(\n        validation_dir,\n        target_size\u003d(150, 150),\n        batch_size\u003d20,\n        class_mode\u003d\u0027binary\u0027)\n\nfor data_batch, labels_batch in train_generator:\n    print(\u0027data batch shape:\u0027, data_batch.shape)\n    print(\u0027labels batch shape:\u0027, labels_batch.shape)\n    break\n\n# Train the data and validate using the two generators from above.\nhistory \u003d model.fit_generator(\n      train_generator,\n      steps_per_epoch\u003d100,\n      epochs\u003d30,\n      validation_data\u003dvalidation_generator,\n      validation_steps\u003d50)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "It is considered good practice to save the model after training, so it can be modified or trained later.",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "model.save(\u0027cats_and_dogs_small_1.h5\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}