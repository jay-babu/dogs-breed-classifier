{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dogs_breed_VGG16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKenbKQt9M7g",
        "colab_type": "text"
      },
      "source": [
        "# Importing all libraries needed for program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dVZgwR_6yth",
        "colab_type": "code",
        "outputId": "caa9bd21-ef18-409a-9ccd-99df377819e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from statistics import mean\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYEF--KCUUfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "download = drive.CreateFile({'id': '1EgZuR10bXkNxK3hg1ppfz_T2aRuUxXwC'})\n",
        "download.GetContentFile('dataset.tar')\n",
        "\n",
        "# model = drive.Create({'id': ''})\n",
        "# model.GetContentFile('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckN0nxLqVjry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf dataset.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUj2b_TD4a__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_cleaner(root):\n",
        "    for path, sub, files in os.walk(root):\n",
        "        if '.ipynb_checkpoints' in path:\n",
        "            shutil.rmtree(path)\n",
        "        for name in files:\n",
        "            if name[0] == '.':\n",
        "                os.remove(os.path.join(path, name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD8grC1UvCAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -a\n",
        "\n",
        "dataset_cleaner(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awhXw_6sXYvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('data/test')\n",
        "\n",
        "!ls -a\n",
        "\n",
        "dataset_cleaner(os.getcwd())\n",
        "\n",
        "os.chdir('../..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVpjVXsPX_ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('data/train')\n",
        "\n",
        "!ls -a\n",
        "dataset_cleaner(os.getcwd())\n",
        "    \n",
        "os.chdir('../..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmXBB7FaYHht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('data/validation')\n",
        "\n",
        "!ls -a\n",
        "dataset_cleaner(os.getcwd())\n",
        "\n",
        "os.chdir('../..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4rwMC5N3g38",
        "colab_type": "text"
      },
      "source": [
        "# Finds the average image width and height"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJr2Xn0z3kta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def width_height_of_images(root='../static/data'):\n",
        "    image_width = []\n",
        "    image_height = []\n",
        "    for path, subdirs, files in os.walk(root):\n",
        "        for name in files:\n",
        "            try:\n",
        "                image = Image.open(os.path.join(path, name))\n",
        "                # print(image.format)\n",
        "                # print(image.size)\n",
        "                width, height = image.size\n",
        "                image_width.append(width)\n",
        "                image_height.append(height)\n",
        "                image.close()\n",
        "            except OSError:\n",
        "                pass\n",
        "            # except UnboundLocalError:\n",
        "            #     print(path, name)\n",
        "            # image.close()\n",
        "    return int(mean(image_width)), int(mean(image_height))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-FZ-JCV9Tnn",
        "colab_type": "text"
      },
      "source": [
        "# Main class for Image Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGJRruPL8sfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dogs = DogBreedTraining('data')\n",
        "# dogs.directory_init()\n",
        "# dogs.image_data_gen(20)\n",
        "\n",
        "# print(dogs.train_generator.class_indices.keys())\n",
        "\n",
        "# dogs.dogs_breed_modeling()\n",
        "# dogs.results()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ga4T-UsFmB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DogBreedTraining:\n",
        "    def __init__(self, base_dir='static/data'):\n",
        "#         plaidml.keras.install_backend()\n",
        "        self.avg_width, self.avg_height = width_height_of_images(base_dir)\n",
        "        self.conv_base = VGG16(weights='imagenet',\n",
        "                               include_top=False,\n",
        "                               input_shape=(256, 256, 3))\n",
        "\n",
        "        base_dir = base_dir\n",
        "\n",
        "        self.train_dir = os.path.join(base_dir, 'train')\n",
        "\n",
        "        self.validation_dir = os.path.join(base_dir, 'train')\n",
        "\n",
        "        self.test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "        self.bulldog = 'bulldog'\n",
        "        self.german_shepherd = 'german_shepherd'\n",
        "        self.golden_retriever = 'golden_retriever'\n",
        "        self.husky = 'husky'\n",
        "        self.poodle = 'poodle'\n",
        "        self.breeds_of_dogs = [self.bulldog, \n",
        "                               self.german_shepherd, \n",
        "                               self.golden_retriever, \n",
        "                               self.husky, \n",
        "                               self.poodle]\n",
        "\n",
        "        self.train_bulldog_dir = None\n",
        "        self.train_german_shepherd_dir = None\n",
        "        self.train_golden_retriever_dir = None\n",
        "        self.train_husky_dir = None\n",
        "        self.train_poodle_dir = None\n",
        "\n",
        "        self.validation_bulldog_dir = None\n",
        "        self.validation_german_shepherd_dir = None\n",
        "        self.validation_golden_retriever_dir = None\n",
        "        self.validation_husky_dir = None\n",
        "        self.validation_poodle_dir = None\n",
        "\n",
        "        self.test_bulldog_dir = None\n",
        "        self.test_german_shepherd_dir = None\n",
        "        self.test_golden_retriever_dir = None\n",
        "        self.test_husky_dir = None\n",
        "        self.test_poodle_dir = None\n",
        "\n",
        "        self.train_generator = None\n",
        "        self.validation_generator = None\n",
        "        self.test_datagen = None\n",
        "\n",
        "        self.history = None\n",
        "\n",
        "    def directory_init(self):\n",
        "        self.train_bulldog_dir = os.path.join(self.train_dir, self.bulldog)\n",
        "        self.train_german_shepherd_dir = os.path.join(self.train_dir, self.german_shepherd)\n",
        "        self.train_golden_retriever_dir = os.path.join(self.train_dir, self.golden_retriever)\n",
        "        self.train_husky_dir = os.path.join(self.train_dir, self.husky)\n",
        "        self.train_poodle_dir = os.path.join(self.train_dir, self.poodle)\n",
        "\n",
        "        self.validation_bulldog_dir = os.path.join(self.validation_dir, self.bulldog)\n",
        "        self.validation_german_shepherd_dir = os.path.join(self.validation_dir, self.german_shepherd)\n",
        "        self.validation_golden_retriever_dir = os.path.join(self.validation_dir, self.golden_retriever)\n",
        "        self.validation_husky_dir = os.path.join(self.validation_dir, self.husky)\n",
        "        self.validation_poodle_dir = os.path.join(self.validation_dir, self.poodle)\n",
        "\n",
        "        self.test_bulldog_dir = os.path.join(self.test_dir, self.bulldog)\n",
        "        self.test_german_shepherd_dir = os.path.join(self.test_dir, self.german_shepherd)\n",
        "        self.test_golden_retriever_dir = os.path.join(self.test_dir, self.golden_retriever)\n",
        "        self.test_husky_dir = os.path.join(self.test_dir, self.husky)\n",
        "        self.test_poodle_dir = os.path.join(self.test_dir, self.poodle)\n",
        "\n",
        "    def image_data_gen(self, batch_size):\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1. / 255,\n",
        "            rotation_range=40, \n",
        "            width_shift_range=0.2, \n",
        "            height_shift_range=0.2, \n",
        "            shear_range=0.2, \n",
        "            zoom_range=0.2, \n",
        "            horizontal_flip=True, \n",
        "            fill_mode='nearest')\n",
        "        \n",
        "        validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "        \n",
        "        self.test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "        self.train_generator = train_datagen.flow_from_directory(\n",
        "            self.train_dir,\n",
        "            target_size=(256, 256),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "        self.validation_generator = validation_datagen.flow_from_directory(\n",
        "            self.validation_dir,\n",
        "            target_size=(256, 256),\n",
        "            batch_size=batch_size,\n",
        "            class_mode='categorical'\n",
        "        )\n",
        "\n",
        "    def dogs_breed_modeling(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(self.conv_base)\n",
        "        model.summary()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation='relu'))\n",
        "        model.add(layers.Dense(5, activation='softmax'))\n",
        "        \n",
        "        print('This is the number of trainable weights ' 'before freezing the conv base:', len(model.trainable_weights))\n",
        "        self.conv_base.trainable = False\n",
        "        print('This is the number of trainable weights ' 'after freezing the conv base:', len(model.trainable_weights))\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        self.history = model.fit_generator(\n",
        "            self.train_generator,\n",
        "            steps_per_epoch=100,\n",
        "            epochs=30,\n",
        "            validation_data=self.validation_generator,\n",
        "            validation_steps=50\n",
        "        )\n",
        "\n",
        "        model.save('dogs_breed_1.h5')\n",
        "    \n",
        "    def dogs_breed_modeling_part_2(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(self.conv_base)\n",
        "        model.summary()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation='relu'))\n",
        "        model.add(layers.Dense(5, activation='softmax'))\n",
        "        \n",
        "        print('This is the number of trainable weights ' 'before freezing the conv base:', len(model.trainable_weights))\n",
        "        self.conv_base.trainable = False\n",
        "        print('This is the number of trainable weights ' 'after freezing the conv base:', len(model.trainable_weights))\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizers.Adam(),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        self.history = model.fit_generator(\n",
        "            self.train_generator,\n",
        "            steps_per_epoch=200,\n",
        "            epochs=100,\n",
        "            validation_data=self.validation_generator,\n",
        "            validation_steps=75\n",
        "        )\n",
        "\n",
        "        model.save('dogs_breed_2.h5')\n",
        "        \n",
        "    def dogs_breed_modeling_part_3(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(self.conv_base)\n",
        "        model.summary()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation='relu'))\n",
        "        model.add(layers.Dense(5, activation='softmax'))\n",
        "        \n",
        "        print('This is the number of trainable weights ' 'before freezing the conv base:', len(model.trainable_weights))\n",
        "        self.conv_base.trainable = False\n",
        "        print('This is the number of trainable weights ' 'after freezing the conv base:', len(model.trainable_weights))\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizers.Adam(lr=0.000125, epsilon=None, \n",
        "                                                decay=0.1, amsgrad=False),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        self.history = model.fit_generator(\n",
        "            self.train_generator,\n",
        "            steps_per_epoch=20,\n",
        "            epochs=50,\n",
        "            validation_data=self.validation_generator,\n",
        "            validation_steps=50\n",
        "        )\n",
        "\n",
        "        model.save('dogs_breed_7.h5')\n",
        "    \n",
        "    def dogs_breed_modeling_part_4(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(self.conv_base)\n",
        "        model.summary()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation='relu'))\n",
        "        model.add(layers.Dense(5, activation='softmax'))\n",
        "        \n",
        "        print('This is the number of trainable weights ' 'before freezing the conv base:', len(model.trainable_weights))\n",
        "        self.conv_base.trainable = False\n",
        "        print('This is the number of trainable weights ' 'after freezing the conv base:', len(model.trainable_weights))\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=optimizers.Adam(lr=0.00002, beta_1=0.9, \n",
        "                                                beta_2=0.999, epsilon=None, \n",
        "                                                decay=0.5, amsgrad=False),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        self.history = model.fit_generator(\n",
        "            self.train_generator,\n",
        "            steps_per_epoch=500,\n",
        "            epochs=250,\n",
        "            validation_data=self.validation_generator,\n",
        "            validation_steps=100\n",
        "        )\n",
        "\n",
        "        model.save('dogs_breed_4.h5')\n",
        "        \n",
        "    def model_evaluate(self):\n",
        "        model = load_model('dogs_breed_4 (1).h5')\n",
        "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        # print(model.predict('static/bulldog/1. Regular/91.Regular.png'))\n",
        "        test_dir = \"static/data/test\"\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "        test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(256, 256),\n",
        "                                                  batch_size=20,\n",
        "                                                  class_mode='categorical')\n",
        "\n",
        "        # predict the result\n",
        "\n",
        "        test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
        "        print(test_loss, test_acc)\n",
        "\n",
        "    def results(self):\n",
        "        acc = self.history.history['acc']\n",
        "        val_acc = self.history.history['val_acc']\n",
        "        loss = self.history.history['loss']\n",
        "        val_loss = self.history.history['val_loss']\n",
        "\n",
        "        epochs = range(1, len(acc) + 1)\n",
        "\n",
        "        plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "        plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "        plt.title('Training and validation accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.figure()\n",
        "\n",
        "        plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "        plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "        plt.title('Training and validation loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeGEeiW3Gkm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dogs_part_2 = DogBreedTraining('data')\n",
        "# dogs_part_2.directory_init()\n",
        "# dogs_part_2.image_data_gen(50)\n",
        "\n",
        "# print(dogs_part_2.train_generator.class_indices.keys())\n",
        "# dogs_part_2.dogs_breed_modeling_part_2()\n",
        "# dogs_part_2.results()\n",
        "\n",
        "# # files.download('dogs_breed_2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysdcQUNbGzlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dogs_part_4 = DogBreedTraining('data')\n",
        "# dogs_part_4.directory_init()\n",
        "# dogs_part_4.image_data_gen(100)\n",
        "\n",
        "# print(dogs_part_4.train_generator.class_indices.keys())\n",
        "# dogs_part_4.dogs_breed_modeling_part_4()\n",
        "# dogs_part_4.results()\n",
        "\n",
        "# files.download('dogs_breed_4.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-KyOSt4GKK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dogs_part_3 = DogBreedTraining('data')\n",
        "dogs_part_3.directory_init()\n",
        "dogs_part_3.image_data_gen(50)\n",
        "\n",
        "print(dogs_part_3.train_generator.class_indices.keys())\n",
        "dogs_part_3.dogs_breed_modeling_part_3()\n",
        "dogs_part_3.results()\n",
        "\n",
        "# files.download('dogs_breed_3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}